---
title: "N-Gram Language Model 2"
author: "Fan Li"
date: "Friday, December 12, 2014"
output: html_document
---

## Objective

Use the full term frequency data to build ngram model and apply more advanced smoothing techniques.


## Key learning

1. 
2.  
3. 


## Load packages and data
```{r setup}
library("slam")  # Sparse matrix
library(microbenchmark)
library(tm)
library(RWeka)
library(microbenchmark)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library("stringr")
library("doParallel")
library("foreach")
library("dplyr")

```

```{r helper_function}
# Helper function to preprocess corpus
CorpusPreprocess <- function(corpus){
  toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
  processed.corpus <- corpus %>%
    tm_map(toSpace, "/|@|\\|()\"") %>%
    #tm_map(content_transformer(tolower)) %>%
    tm_map(removeNumbers) %>%
    #tm_map(removePunctuation) %>%
    tm_map(stripWhitespace)
  return(processed.corpus)
}

```

```{r load_data}
load(file="../../DSCapstoneProject_Data/Output/RData/1gram.RData")  # merged.1gram
load(file="../../DSCapstoneProject_Data/Output/RData/2gram.RData")  # merged.2gram
load(file="../../DSCapstoneProject_Data/Output/RData/3gram.RData")  # merged.3gram

```



## Build ngram model

```{r ngram_laplace_smoothing}
WordChooser <- function(words, phrase, dict.grams=list(merged.1gram, merged.2gram, merged.3gram)){
  word.prob <- data_frame(words=tolower(words), gram.1=NA, gram.2=NA, gram.3=NA)
  
  phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
  phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
  
  if(length(phrase) > 2)
    phrase <- phrase[(length(phrase)-1): length(phrase)]

  print(phrase)
  for(i in 1:length(words)){
    word <- word.prob$words[i]
    #print(word)
    word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
    for(j in 1:length(phrase)){
      phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
      if(!phrase.seg %in% names(dict.grams[[j]])){
        #print(paste(phrase.seg, "not in ngrams."))
        next
      }      
      #print(dict.grams[[j+1]][paste(phrase.seg, word)])
      word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
      
    }
  }
  return(word.prob)
}


phrase <- "The guy in front of me just bought a pound of bacon, a bouquet, and a case of"
words <- c("cheese", "beer", "pretzels", "soda")

WordChooser(words, phrase) %>%
  arrange(-gram.3, -gram.2, -gram.1) 

phrase <- "You're the reason why I smile everyday. Can you follow me please? It would mean the"
words <- c("most", "best", "universe", "world")

WordChooser(words, phrase) %>%
  arrange(-gram.3, -gram.2, -gram.1) 

phrase <- "Hey sunshine, can you follow me and make me the"
words <- c("smelliest", "bluest", "happiest", "saddest")

WordChooser(words, phrase) %>%
  arrange(-gram.3, -gram.2, -gram.1) 
```

```{r ngram_size}
ngram.size <- data.frame(limit=1, size=as.integer(object.size(merged.3gram)))

for(i in seq(2, 10, 1)){
  ngram.size <- rbind(ngram.size,
                      data.frame(limit=i, size=as.integer(object.size(merged.3gram[merged.3gram>=i]))))
}

ggplot(ngram.size, aes(x=limit, y=size)) +
  geom_line(size=1.5) +
  geom_point(size=4)

```



```{r data_table}
library("data.table")

merged.3gram <- merged.3gram[merged.3gram>1]  # Limit to count > 1 only
merged.3gram <- merged.3gram[str_detect(names(merged.3gram), "^[A-z]+\\s+[A-z]+\\s+[A-z]+$")]  # Remove non-alphabet

df.3gram <- data_frame(key = str_replace_all(names(merged.3gram), "(^[A-z]+\\s+[A-z]+)\\s+[A-z]+$", "\\1"),
                       word = str_replace_all(names(merged.3gram), "^[A-z]+\\s+[A-z]+\\s+([A-z]+)$", "\\1"), 
                       count = merged.3gram) %>%
  group_by(key) %>%
  arrange(-count) %>%
  filter(row_number() <= 5) 

dt.3gram <- data.table(df.3gram)
setkey(dt.3gram, key)


merged.2gram <- merged.2gram[merged.2gram>1]  # Limit to count > 1 only
merged.2gram <- merged.2gram[str_detect(names(merged.2gram), "^[A-z]+\\s+[A-z]+$")]  # Remove non-alphabet

df.2gram <- data_frame(key = str_replace_all(names(merged.2gram), "(^[A-z]+)\\s+[A-z]+$", "\\1"),
                       word = str_replace_all(names(merged.2gram), "^[A-z]+\\s+([A-z]+)$", "\\1"), 
                       count = merged.2gram) %>%
  group_by(key) %>%
  arrange(-count) %>%
  filter(row_number() <= 5) 

dt.2gram <- data.table(df.2gram)
setkey(dt.2gram, key)

merged.1gram <- merged.1gram[str_detect(names(merged.1gram), "^[A-z]+$")] 
merged.1gram <- sort(merged.1gram, decreasing=TRUE)[1:100]
dt.1gram <- data.table(data_frame(key=names(merged.1gram), word=names(merged.1gram), count=merged.1gram))
setkey(dt.1gram, key)

save(dt.1gram, dt.2gram, dt.3gram, file="../Output/gram_dt.RData")
#save(dt.1gram, dt.2gram, dt.3gram, file="data/gram_dt.RData")
```


```{r prediction}
# Helper function to generate prediction result
Predict.Word <- function(word.1, word.2){
  pred.3gram <- dt.3gram[key==paste(word.1, word.2)]
  
  if(nrow(pred.3gram) < 5){
    pred.2gram <- dt.2gram[key==word.2]
    if((length(unique(c(pred.3gram$word, pred.2gram$word)))) < 5){
      result <- c(pred.3gram$word, 
                  pred.2gram$word[!pred.2gram$word %in% pred.3gram$word], 
                  dt.1gram$word[!dt.1gram$word %in% pred.3gram$word & !dt.1gram$word %in% pred.2gram$word][1:(5-length(unique(c(pred.3gram$word, pred.2gram$word))))])
    }else{
      result <- c(pred.3gram$word, pred.2gram$word[!pred.2gram$word %in% pred.3gram$word][1:(5-nrow(pred.3gram))])
    }
  }else{
    result <- pred.3gram$word[1:5]
  }
  return(result)
}

# Helper function to continuously predict a whole phrase
Predict.Phrase <- function(phrase){
  phrase.tr <- as.character((VCorpus(VectorSource(phrase)) %>% CorpusPreprocess())[[1]])
  words <- strsplit(phrase.tr, " ")[[1]] %>%
    str_replace_all("[,|.|?|!]", "")
  prediction <- data_frame(ind=1:length(words), word=words[1:length(words)], predict.1=NA, predict.2=NA, predict.3=NA, predict.4=NA, predict.5=NA, score=NA)

  for(i in 3:length(words)){
    #print(i)
    result <- Predict.Word(words[i-2], words[i-1])
    prediction[i, 3:7] <- result
    if(words[i] %in% result){
      prediction[i, 8] <- 6-which(result==words[i]) 
    }else{
      prediction[i, 8] <- 0
    }
  }
  return(prediction)
}


Predict.Phrase("The guy in front of me just bought a pound of bacon, a bouquet, and a case of beer.")

Predict.Phrase("You're the reason why I smile everyday. Can you follow me please? It would mean the world.")

Predict.Phrase("Hey sunshine, can you follow me and make me the happiest.")

```


```{r sample_news}
f <- file("../../DSCapstoneProject_Data/Data/final/en_US/en_US.news.txt", "rb")
en_us.news <- readLines(f, encoding="UTF-8")
close(f)

set.seed(123)
sample.news <- en_us.news[sample(length(en_us.news), 500)]
sample.news <- str_replace_all(sample.news, "\\\"", "")  # Remove "\"" in some text
sample.news <- str_replace_all(sample.news, "^([^.|?|!]+[.|?|!])[^\n]*", "\\1")  # Keep the first sentence only
sample.news <- sample.news[!str_detect(sample.news, "\\d")]
sample.news <- sample.news[nchar(sample.news)>100 & nchar(sample.news)<150]

save(sample.news, file="sample_news.RData")


```








