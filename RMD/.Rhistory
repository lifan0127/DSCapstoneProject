word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]]))
print(paste(phrase.seg, "not in ngrams."))
next
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
word.prob
words <- c("States", "Nations")
phrase <- "we are in the United"
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
phrase
words <- c("States", "Nations")
phrase <- "we are in the United"
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
phrase
i=1
j=1
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
word.prob
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
phrase.seg %in% names(dict.grams[[j]])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
word.prob
j=2
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
phrase.seg
phrase.seg %in% names(dict.grams[[j]])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
word.prob
j=3
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
phrase.seg %in% names(dict.grams[[j]])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
word.prob
words <- c("States", "Nations")
phrase <- "we are in the United"
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]]))
print(paste(phrase.seg, "not in ngrams."))
next
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
word.prob
words <- c("States")
phrase <- "we are in the United"
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]]))
print(paste(phrase.seg, "not in ngrams."))
next
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
word.prob
i=1
words <- c("States")
phrase <- "we are in the United"
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
phrase
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]]))
print(paste(phrase.seg, "not in ngrams."))
next
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
word.prob
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]]))
print(paste(phrase.seg, "not in ngrams."))
next
print(sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
for(j in 1:length(phrase)){
print(j)
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]]))
print(paste(phrase.seg, "not in ngrams."))
next
print(sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
for(j in 1:length(phrase)){
print(j)
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
word.prob
words <- c("States", "Nations")
phrase <- "we are in the United"
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
print(j)
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
}
WordChooser(words, phrase)
words <- c("States", "Nations")
phrase <- "we are in the United"
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
print(j)
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
phrase <- "we are in the United"
WordChooser(words, phrase)
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
print(j)
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
WordChooser(words, phrase)
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
print(sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE))
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
WordChooser(words, phrase)
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
print(dict.grams[[j+1]][paste(phrase.seg, word)])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
WordChooser(words, phrase)
words <- c("States", "Nations")
phrase <- "we are in the United"
word.prob <- data_frame(words, gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
i=1
word <- word.prob$words[i]
print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
j=1
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
phrase.seg
phrase.seg %in% names(dict.grams[[j]])
print(dict.grams[[j+1]][paste(phrase.seg, word)])
paste(phrase.seg, word)
word.prob <- data_frame(tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
word <- word.prob$words[i]
word
words <- c("States", "Nations")
word.prob <- data_frame(tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
word.prob
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
print(dict.grams[[j+1]][paste(phrase.seg, word)])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
i=1
word <- word.prob$words[i]
word
word.prob <- data_frame(tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
word.prob
word.prob <- data_frame(words=tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
words <- c("States", "Nations")
phrase <- "we are in the United"
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words=tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
print(dict.grams[[j+1]][paste(phrase.seg, word)])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
WordChooser(words, phrase)
WordChooser(c("cheese", "beer", "pretzels", "soda"), "The guy in front of me just bought a pound of bacon, a bouquet, and a case of")
words <- c("cheese", "beer", "pretzels", "soda")
phrase <- "The guy in front of me just bought a pound of bacon, a bouquet, and a case of"
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words=tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
#print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
print(paste(phrase.seg, "not in ngrams."))
next
}
#print(dict.grams[[j+1]][paste(phrase.seg, word)])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1) %>%
filter(row_number()==1)
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1) %>%
filter(row_number()==1)$words
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1) %>%
filter(row_number()==1) %>%
select(words)
phrase <- "You're the reason why I smile everyday. Can you follow me please? It would mean the"
words <- c("most", "best", "universe", "world")
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1) %>%
filter(row_number()==1) %>%
select(words)
WordChooser(words, phrase)
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1)
phrase <- "Hey sunshine, can you follow me and make me the"
words <- c("smelliest", "bluest", "happiest", "saddest")
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1) %>%
filter(row_number()==1) %>%
select(words)
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1)
news <- en_us.news[sample(length(en_us.news), 100000)]
# Helper function to preprocess corpus
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
CorpusPreprocess <- function(corpus){
processed.corpus <- corpus %>%
tm_map(toSpace, "/|@|\\|") %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
return(processed.corpus)
}
# Data preprocessing in parallel
core <- 4
cl <- makeCluster(core)
registerDoParallel(cl)
news.list <- split(news, sample(rep(1:core, ceiling(length(news)/core))[1:length(news)]))
result.list <- foreach(k = 1:core, .packages=c("dplyr", "tm", "RWeka")) %dopar% {
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
TetragramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 4, max = 4))
news.corpus <- VCorpus(VectorSource(news.list[[k]])) %>% CorpusPreprocess()
news.dtm <- DocumentTermMatrix(news.corpus, control=list(wordLengths=c(1,Inf)))
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = BigramTokenizer))
news.dtm.3g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TrigramTokenizer))
news.dtm.4g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TetragramTokenizer))
list(news.corpus, news.dtm, news.dtm.2g, news.dtm.3g, news.dtm.4g)
}
# Helper function to preprocess corpus
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
CorpusPreprocess <- function(corpus){
processed.corpus <- corpus %>%
tm_map(toSpace, "/|@|\\|") %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
return(processed.corpus)
}
# Data preprocessing in parallel
core <- 8
cl <- makeCluster(core)
registerDoParallel(cl)
news.list <- split(news, sample(rep(1:core, ceiling(length(news)/core))[1:length(news)]))
result.list <- foreach(k = 1:core, .packages=c("dplyr", "tm", "RWeka")) %dopar% {
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
TetragramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 4, max = 4))
news.corpus <- VCorpus(VectorSource(news.list[[k]])) %>% CorpusPreprocess()
news.dtm <- DocumentTermMatrix(news.corpus, control=list(wordLengths=c(1,Inf)))
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = BigramTokenizer))
news.dtm.3g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TrigramTokenizer))
news.dtm.4g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TetragramTokenizer))
list(news.corpus, news.dtm, news.dtm.2g, news.dtm.3g, news.dtm.4g)
}
stopCluster(cl)
# Merge corpus and dtm's (http://stackoverflow.com/a/20971354)
news.corpus <- do.call(function(...) c(..., recursive = TRUE), lapply(result.list, function(x) x[[1]]))
news.dtm <- do.call(function(...) c(..., recursive = TRUE), lapply(result.list, function(x) x[[2]]))
news.dtm.2g <- do.call(function(...) c(..., recursive = TRUE), lapply(result.list, function(x) x[[3]]))
news.dtm.3g <- do.call(function(...) c(..., recursive = TRUE), lapply(result.list, function(x) x[[4]]))
news.dtm.4g <- do.call(function(...) c(..., recursive = TRUE), lapply(result.list, function(x) x[[5]]))
dict.1gram <- news.dtm %>%
removeSparseTerms(0.999) %>%  # 3321 1-grams
MostFreq()
dict.2gram <- news.dtm.2g %>%
removeSparseTerms(0.9995) %>%  # 7035 2-grams
MostFreq()
dict.3gram <- news.dtm.3g %>%
removeSparseTerms(0.99975) %>%  # 4697 3-grams
MostFreq()
dict.4gram <- news.dtm.4g %>%
removeSparseTerms(0.9998) %>%  # 3043 4-grams
MostFreq()
dict.2gram <- news.dtm.2g %>%
removeSparseTerms(0.999) %>%  # 7035 2-grams
MostFreq()
WordChooser <- function(words, phrase, dict.grams=list(dict.1gram, dict.2gram, dict.3gram, dict.4gram)){
word.prob <- data_frame(words=tolower(words), gram.1=NA, gram.2=NA, gram.3=NA, gram.4=NA)
phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()
phrase <- str_split(as.character(phrase[[1]]), " ")[[1]]
if(length(phrase) > 3)
phrase <- phrase[(length(phrase)-2): length(phrase)]
for(i in 1:length(words)){
word <- word.prob$words[i]
#print(word)
word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])
for(j in 1:length(phrase)){
phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=" ")
if(!phrase.seg %in% names(dict.grams[[j]])){
#print(paste(phrase.seg, "not in ngrams."))
next
}
#print(dict.grams[[j+1]][paste(phrase.seg, word)])
word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]
}
}
return(word.prob)
}
phrase <- "The guy in front of me just bought a pound of bacon, a bouquet, and a case of"
words <- c("cheese", "beer", "pretzels", "soda")
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1)
phrase <- "You're the reason why I smile everyday. Can you follow me please? It would mean the"
words <- c("most", "best", "universe", "world")
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1)
phrase <- "Hey sunshine, can you follow me and make me the"
words <- c("smelliest", "bluest", "happiest", "saddest")
WordChooser(words, phrase) %>%
arrange(-gram.4, -gram.3, -gram.2, -gram.1)
news <- en_us.news[sample(length(en_us.news), 10000)]
# Data preprocessing in parallel
core <- 8
cl <- makeCluster(core)
registerDoParallel(cl)
news.list <- split(news, sample(rep(1:core, ceiling(length(news)/core))[1:length(news)]))
result.list <- foreach(k = 1:core*10, .packages=c("dplyr", "tm", "RWeka")) %dopar% {
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
TetragramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 4, max = 4))
news.corpus <- VCorpus(VectorSource(news.list[[k]])) %>% CorpusPreprocess()
news.dtm <- DocumentTermMatrix(news.corpus, control=list(wordLengths=c(1,Inf)))
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = BigramTokenizer))
news.dtm.3g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TrigramTokenizer))
news.dtm.4g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TetragramTokenizer))
list(news.corpus, news.dtm, news.dtm.2g, news.dtm.3g, news.dtm.4g)
}
stopCluster(cl)
