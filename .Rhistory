f <- file("../Data/final/en_US/en_US.news.txt", "rb")
en_us.news <- readLines(f)
close(f)
setwd("~/GitHub/DSCapstoneProject/RMD")
f <- file("../Data/final/en_US/en_US.news.txt", "rb")
en_us.news <- readLines(f)
close(f)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus.preprocess <- function(corpus){
# Helper function to preprocess corpus
processed.corpus <- corpus %>%
tm_map(toSpace, "/|@|\\|") %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stripWhitespace)
return(processed.corpus)
}
news.corpus <- VCorpus(VectorSource(en_us.news)) %>% corpus.preprocess()
news.dtm <- DocumentTermMatrix(news.corpus) %>% removeSparseTerms(0.95)
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = NGramTokenizer(x, Weka_control(min = 2, max = 2)))) %>% removeSparseTerms(0.995)
library(tm)
library(RWeka)
library(dplyr)
library(tm)
library(RWeka)
library(dplyr)
f <- file("../Data/final/en_US/en_US.news.txt", "rb")
en_us.news <- readLines(f)
close(f)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus.preprocess <- function(corpus){
# Helper function to preprocess corpus
processed.corpus <- corpus %>%
tm_map(toSpace, "/|@|\\|") %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stripWhitespace)
return(processed.corpus)
}
news.corpus <- VCorpus(VectorSource(en_us.news)) %>% corpus.preprocess()
f <- file("../Data/final/en_US/en_US.news.txt", "rb")
en_us.news <- readLines(f)
close(f)
set.seed(123)
news <- sample(en_us.news, length(en_us.news)*0.05)
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
corpus.preprocess <- function(corpus){
# Helper function to preprocess corpus
processed.corpus <- corpus %>%
tm_map(toSpace, "/|@|\\|") %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stripWhitespace)
return(processed.corpus)
}
news.corpus <- VCorpus(VectorSource(news)) %>% corpus.preprocess()
news.dtm <- DocumentTermMatrix(news.corpus) %>% removeSparseTerms(0.95)
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = NGramTokenizer(x, Weka_control(min = 2, max = 2)))) %>% removeSparseTerms(0.995)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = BigramTokenizer)) %>% removeSparseTerms(0.99)
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
news.dtm.3g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TrigramTokenizer)) %>% removeSparseTerms(0.999)
news[1:5]
news.dtm[1:5]
news.dtm[1:5, ]
as.matrix(news.dtm)[1:5, ]
news.dtm
news.dtm <- DocumentTermMatrix(news.corpus)
BigramTokenizer
news.dtm.2g
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = BigramTokenizer))
news.dtm.3g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TrigramTokenizer))
install.packages("gridExtra")
library(ggplot2)
library(gridExtra)
record.length <- data.frame(character=nchar(news), word=rowSums(as.matrix(news.dtm)))
p1 <- ggplot(record.length, aes(x=character)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
p2 <- ggplot(record.length, aes(x=word)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
grid.arrange(p1, p2, ncol=2)
record.length <- data.frame(character=nchar(news), word=rowSums(as.matrix(news.dtm)))
p1 <- ggplot(record.length, aes(x=character)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
p2 <- ggplot(record.length, aes(x=word)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
grid.arrange(p1, p2, ncol=2)
record.length <- data.frame(character=nchar(news), word=rowSums(as.matrix(news.dtm)))
p1 <- ggplot(record.length, aes(x=character)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
record.length <- data.frame(character=nchar(news), word=rowSums(as.matrix(news.dtm)))
nchar(news)
length(nchar(news))
length(rowSums(as.matrix(news.dtm)))
news.dtm
rowSums(as.matrix(news.dtm))
rowSums(as.matrix(news.dtm), na.rm=TRUE)
nas.matrix(news.dtm)
as.matrix(news.dtm)
colSums(as.matrix(news.dtm))
news.dtm
as.matrix(news.dtm)
install.packages("slam")
record.length <- data.frame(character=nchar(news), word=length(strsplit(news, " ")))
head(record.length)
a <- strsplit(news, " ")
class(a)
record.length <- data.frame(character=nchar(news), word=lapply(strsplit(news, " "), length))
sapply(strsplit(news, " "), length)
record.length <- data.frame(character=nchar(news), word=sapply(strsplit(news, " "), length))
head(record.length)
p1 <- ggplot(record.length, aes(x=character)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
p2 <- ggplot(record.length, aes(x=word)) +
geom_bar(stat="bin", binwidth=5) +
theme_bw() +
ggtitle("Record Length by Character")
grid.arrange(p1, p2, ncol=2)
a < removeSparseTerms(news.dtm, 0.9)
a <- removeSparseTerms(news.dtm, 0.9)
a
a <- removeSparseTerms(news.dtm, 0.99)
a
news.dtm <- DocumentTermMatrix(news.corpus) %>% removeSparseTerms(0.99)
most.freq <- function(dtm, n=5){
freq <- colSums(as.matrix(dtm))
return(freq[order(freq, decreasing=TRUE)][1:n])
}
most.freq(news.dtm)
most.freq <- function(dtm, n=10){
freq <- colSums(as.matrix(dtm))
return(freq[order(freq, decreasing=TRUE)][1:n])
}
most.freq(news.dtm)
names(most.freq(news.dtm))
most.freq <- function(dtm, n=10){
freq <- colSums(as.matrix(dtm))
result <- freq[order(freq, decreasing=TRUE)][1:n]
return(data.frame(term=names(result), count=result))
}
most.freq(news.dtm)
most.freq <- function(dtm, n=10){
freq <- colSums(as.matrix(dtm))
result <- freq[order(freq, decreasing=TRUE)][1:n]
return(data_frame(term=names(result), count=result))
}
most.freq(news.dtm)
?data_frame
library(devtools)
session_info
session_info()
session_info()
sessionInfo()
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
most.freq <- function(dtm, n=10){
freq <- colSums(as.matrix(dtm))
result <- freq[order(freq, decreasing=TRUE)][1:n]
return(data_frame(term=names(result), count=result))
}
most.freq(news.dtm)
?data_frames
library(dplyr)
?data_frame
most.freq <- function(dtm, n=10){
freq <- colSums(as.matrix(dtm))
result <- freq[order(freq, decreasing=TRUE)][1:n]
return(data_frame(term=names(result), count=result))
}
most.freq(news.dtm)
ggplot(most.freq(news.dtm), aes(x=term, y=count)) +
geom_bar(stat="identity") +
theme_bw()
library(ggplot2)
library(tm)
library(RWeka)
library(ggplot2)
library(gridExtra)
library(dplyr)  # version 0.3 required
ggplot(most.freq(news.dtm), aes(x=term, y=count)) +
geom_bar(stat="identity") +
theme_bw()
ggplot(most.freq(news.dtm), aes(x=reorder(term, count), y=count)) +
geom_bar(stat="identity") +
theme_bw()
ggplot(most.freq(news.dtm), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw()
ggplot(most.freq(news.dtm.2g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw()
news.dtm.2g <- DocumentTermMatrix(news.corpus, control=list(tokenize = BigramTokenizer)) %>% removeSparseTerms(0.9999)
ggplot(most.freq(news.dtm.2g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
ggtitle("Most frequent 2-gram in news")
ggplot(most.freq(news.dtm.2g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
scale_x_discrete(name="") +
ggtitle("Most frequent 2-gram in news")
ggplot(most.freq(news.dtm), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5, size=16))
ggtitle("Most frequent words in news")
ggplot(most.freq(news.dtm), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5))
ggtitle("Most frequent words in news")
ggplot(most.freq(news.dtm), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
ggtitle("Most frequent words in news")
ggplot(most.freq(news.dtm), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank()) +
ggtitle("Most frequent words in news")
ggplot(most.freq(news.dtm.2g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5))
ggtitle("Most frequent 2-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, vjust=1))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, vjust=0.5))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.2g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5))
ggtitle("Most frequent 2-gram in news")
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
news.dtm.3g <- DocumentTermMatrix(news.corpus, control=list(tokenize = TrigramTokenizer)) %>% removeSparseTerms(0.9999)
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, vjust=0.5))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, vjust=1))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, vjust=0))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, hjust=0))
ggtitle("Most frequent 3-gram in news")
ggplot(most.freq(news.dtm.3g), aes(x=reorder(term, -count), y=count)) +
geom_bar(stat="identity") +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=45, hjust=1))
ggtitle("Most frequent 3-gram in news")
install.packages("bitops")
library("bitops", lib.loc="~/R/win-library/3.1")
library("RCurl", lib.loc="~/R/win-library/3.1")
