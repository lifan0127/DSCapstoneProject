{
    "contents" : "---\ntitle: \"N-Gram Language Model 2\"\nauthor: \"Fan Li\"\ndate: \"Friday, December 12, 2014\"\noutput: html_document\n---\n\n## Objective\n\nUse the full term frequency data to build ngram model and apply more advanced smoothing techniques.\n\n\n## Key learning\n\n1. \n2.  \n3. \n\n\n## Load packages and data\n```{r setup}\nlibrary(\"slam\")  # Sparse matrix\nlibrary(microbenchmark)\nlibrary(tm)\nlibrary(RWeka)\nlibrary(microbenchmark)\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(RColorBrewer)\nlibrary(\"stringr\")\nlibrary(\"doParallel\")\nlibrary(\"foreach\")\nlibrary(\"dplyr\")\n\n```\n\n```{r helper_function}\n# Helper function to preprocess corpus\nCorpusPreprocess <- function(corpus){\n  toSpace <- content_transformer(function(x, pattern) gsub(pattern, \" \", x))\n  processed.corpus <- corpus %>%\n    tm_map(toSpace, \"/|@|\\\\|()\\\"\") %>%\n    #tm_map(content_transformer(tolower)) %>%\n    tm_map(removeNumbers) %>%\n    #tm_map(removePunctuation) %>%\n    tm_map(stripWhitespace)\n  return(processed.corpus)\n}\n\n```\n\n```{r load_data}\nload(file=\"../../DSCapstoneProject_Data/Output/RData/1gram.RData\")  # merged.1gram\nload(file=\"../../DSCapstoneProject_Data/Output/RData/2gram.RData\")  # merged.2gram\nload(file=\"../../DSCapstoneProject_Data/Output/RData/3gram.RData\")  # merged.3gram\n\n```\n\n\n\n## Build ngram model\n\n```{r ngram_laplace_smoothing}\nWordChooser <- function(words, phrase, dict.grams=list(merged.1gram, merged.2gram, merged.3gram)){\n  word.prob <- data_frame(words=tolower(words), gram.1=NA, gram.2=NA, gram.3=NA)\n  \n  phrase <- VCorpus(VectorSource(phrase)) %>% CorpusPreprocess()\n  phrase <- str_split(as.character(phrase[[1]]), \" \")[[1]]\n  \n  if(length(phrase) > 2)\n    phrase <- phrase[(length(phrase)-1): length(phrase)]\n\n  print(phrase)\n  for(i in 1:length(words)){\n    word <- word.prob$words[i]\n    #print(word)\n    word.prob$gram.1[i] <- sum(dict.grams[[1]][word], 1, na.rm=TRUE)/sum(dict.grams[[1]])\n    for(j in 1:length(phrase)){\n      phrase.seg <- paste(phrase[(length(phrase)-j+1): length(phrase)], collapse=\" \")\n      if(!phrase.seg %in% names(dict.grams[[j]])){\n        #print(paste(phrase.seg, \"not in ngrams.\"))\n        next\n      }      \n      #print(dict.grams[[j+1]][paste(phrase.seg, word)])\n      word.prob[i, j+2] <- sum(dict.grams[[j+1]][paste(phrase.seg, word)], 1, na.rm=TRUE)/dict.grams[[j]][phrase.seg]\n      \n    }\n  }\n  return(word.prob)\n}\n\n\nphrase <- \"The guy in front of me just bought a pound of bacon, a bouquet, and a case of\"\nwords <- c(\"cheese\", \"beer\", \"pretzels\", \"soda\")\n\nWordChooser(words, phrase) %>%\n  arrange(-gram.3, -gram.2, -gram.1) \n\nphrase <- \"You're the reason why I smile everyday. Can you follow me please? It would mean the\"\nwords <- c(\"most\", \"best\", \"universe\", \"world\")\n\nWordChooser(words, phrase) %>%\n  arrange(-gram.3, -gram.2, -gram.1) \n\nphrase <- \"Hey sunshine, can you follow me and make me the\"\nwords <- c(\"smelliest\", \"bluest\", \"happiest\", \"saddest\")\n\nWordChooser(words, phrase) %>%\n  arrange(-gram.3, -gram.2, -gram.1) \n```\n\n```{r ngram_size}\nngram.size <- data.frame(limit=1, size=as.integer(object.size(merged.3gram)))\n\nfor(i in seq(2, 10, 1)){\n  ngram.size <- rbind(ngram.size,\n                      data.frame(limit=i, size=as.integer(object.size(merged.3gram[merged.3gram>=i]))))\n}\n\nggplot(ngram.size, aes(x=limit, y=size)) +\n  geom_line(size=1.5) +\n  geom_point(size=4)\n\n```\n\n\n\n```{r data_table}\nlibrary(\"data.table\")\n\nmerged.3gram <- merged.3gram[merged.3gram>1]  # Limit to count > 1 only\nmerged.3gram <- merged.3gram[str_detect(names(merged.3gram), \"^[A-z]+\\\\s+[A-z]+\\\\s+[A-z]+$\")]  # Remove non-alphabet\n\ndf.3gram <- data_frame(key = str_replace_all(names(merged.3gram), \"(^[A-z]+\\\\s+[A-z]+)\\\\s+[A-z]+$\", \"\\\\1\"),\n                       word = str_replace_all(names(merged.3gram), \"^[A-z]+\\\\s+[A-z]+\\\\s+([A-z]+)$\", \"\\\\1\"), \n                       count = merged.3gram) %>%\n  group_by(key) %>%\n  arrange(-count) %>%\n  filter(row_number() <= 5) \n\ndt.3gram <- data.table(df.3gram)\nsetkey(dt.3gram, key)\n\n\nmerged.2gram <- merged.2gram[merged.2gram>1]  # Limit to count > 1 only\nmerged.2gram <- merged.2gram[str_detect(names(merged.2gram), \"^[A-z]+\\\\s+[A-z]+$\")]  # Remove non-alphabet\n\ndf.2gram <- data_frame(key = str_replace_all(names(merged.2gram), \"(^[A-z]+)\\\\s+[A-z]+$\", \"\\\\1\"),\n                       word = str_replace_all(names(merged.2gram), \"^[A-z]+\\\\s+([A-z]+)$\", \"\\\\1\"), \n                       count = merged.2gram) %>%\n  group_by(key) %>%\n  arrange(-count) %>%\n  filter(row_number() <= 5) \n\ndt.2gram <- data.table(df.2gram)\nsetkey(dt.2gram, key)\n\nmerged.1gram <- merged.1gram[str_detect(names(merged.1gram), \"^[A-z]+$\")] \nmerged.1gram <- sort(merged.1gram, decreasing=TRUE)[1:100]\ndt.1gram <- data.table(data.frame(key=names(merged.1gram), word=names(merged.1gram), count=merged.1gram))\nsetkey(dt.1gram, key)\n\nsave(dt.1gram, dt.2gram, dt.3gram, file=\"../Output/gram_dt.RData\")\n\n```\n\n\n```{r prediction}\nphrase <- \"The guy in front of me just bought a pound of bacon, a bouquet, and a case of beer.\"\n\nphrase.tr <- as.character((VCorpus(VectorSource(phrase)) %>% CorpusPreprocess())[[1]])\n\nwords <- strsplit(phrase.tr, \" \")[[1]] %>%\n  str_replace_all(\"[,|.|?|!]\", \"\")\n\nprediction <- data.frame(ind=1:length(words), word=words[1:length(words)], predict.1=NA, predict.2=NA, predict.3=NA, predict.4=NA, predict.5=NA, score=NA)\n\nfor(i in 3:length(words)){\n  #print(i)\n  pred.3gram <- dt.3gram[key==paste(words[i-2], words[i-1])]\n  \n  if(nrow(pred.3gram) < 5){\n    pred.2gram <- dt.2gram[key==words[i-1]]\n    if((length(unique(c(pred.3gram$word, pred.2gram$word)))) < 5){\n      result <- c(pred.3gram$word, \n                  pred.2gram$word[!pred.2gram$word %in% pred.3gram$word][1:(5-nrow(pred.3gram))], \n                  dt.1gram$word[!pred.1gram$word %in% pred.3gram$word & !pred.1gram$word %in% pred.2gram$word][1:(5-length(unique(c(pred.3gram$word, pred.2gram$word))))])\n    }else{\n      result <- c(pred.3gram$word, pred.2gram$word[!pred.2gram$word %in% pred.3gram$word][1:(5-nrow(pred.3gram))])\n    }\n  }else{\n    result <- pred.3gram$word[1:5]\n  }\n  prediction[i, 3:7] <- result\n  if(words[i] %in% result){\n    prediction[i, 8] <- 6-which(result==words[i]) \n  }else{\n    prediction[i, 8] <- 0\n  }\n}\n\n\n\n```\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1418443843976.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1782585394",
    "id" : "9222DB7B",
    "lastKnownWriteTime" : 1418527819,
    "path" : "~/GitHub/DSCapstoneProject/RMD/ngram_model_v2.Rmd",
    "project_path" : "RMD/ngram_model_v2.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_markdown"
}